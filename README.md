# Prueba T茅cnica para DevOps Senior
Configurar una arquitectura en AWS para soportar un modelo de transcripci贸n basado en IA, requiere configurar credenciales AWS con `aws-cli` para gestionar recursos.

### Requirements
- `Python`: 3.8.x and greater
- `Terraform`: 1.10.4 latest
- `Docker`: 

### Getting Started
A continuaci贸n, presento los pasos principales con scripts [`Terraform`](https://www.terraform.io/) (`/tf/main.tf`) que puedes replicar para implementar la misma arquitectura planteada.
```bash
    terraform init
    terraform validate
    terraform apply
```


## 1. Infraestructura en la Nube
Terraform mostrar谩 los valores como el ID del bucket S3, el nombre del cl煤ster EKS y el ID de la instancia EC2 creada (`outputs.tf`).
```hcl
    output "s3_bucket_name" {
    value = aws_s3_bucket.data_bucket.id
    }
    output "eks_cluster_name" {
    value = module.eks.cluster_name
    }
    output "ec2_instance_id" {
    value = aws_instance.ml_ec2.id
    }
```
En general, la arquitectura planteada es la siguiente [`Excalidraw Source`](https://excalidraw.com/),
![cloud_infrastructure](assets/terraform.png)



## 2. Pipeline de CI/CD
Una soluci贸n basada en **GitHub Actions** que implementa un pipeline CI/CD para el despliegue de un modelo de transcripci贸n en un cl煤ster de EKS. Este pipeline incluye pruebas unitarias, construcci贸n de im谩genes Docker y despliegue automatizado.
   ```bash
   eksctl create cluster -f eks/cluster-config.yaml
   ```
### Configuration
1. **Secretos en GitHub**: `AWS_ACCESS_KEY_ID` y `AWS_SECRET_ACCESS_KEY` son credenciales de AWS.
2. **Manifiestos Kubernetes**: `deployment.yaml` y `service.yaml` con las configuraciones necesarias.
3. **Imagenes Docker**: `prueba_tecnica_devops.git` repositorio para almacenar las im谩genes Docker del modelo.
4. **Cl煤ster EKS**: Tener configurado un cl煤ster EKS con los permisos necesarios para el despliegue.



## 3. Gesti贸n de Datos y Data Warehouse 
El pipeline propuesto consta de tres componentes principales:
- Extracci贸n de datos desde S3: Un evento en S3 (subida de un archivo) activa la funci贸n Lambda.
- Procesamiento de datos mediante `Lambda Functions`:
   - La funci贸n Lambda procesa la grabaci贸n (transcripci贸n, extracci贸n de metadatos, etc.).
   - Los resultados se formatean en `TABLE`, `JSON` o `CSV` para su carga.
- Carga en Amazon Redshift: La funci贸n Lambda utiliza la funcionalidad de `COPY` de Redshift para cargar los datos procesados al data warehouse.

### Amazon Redshift
Esquema de la base de datos con los campos `text` para la transcripci贸n y `timestamp` para verificar la hora de subida y procesamiento,
```sql
CREATE TABLE transcription_results (
    id VARCHAR(50) PRIMARY KEY,
    text TEXT,
    timestamp TIMESTAMP
);
```

### Permisos IAM
Roles y pol铆ticas necesarias para acceder a S3 y Redshift.
![IAM Polities](assets/iam.png)
1. VPC Lambda: Configurar Lambda para ejecutarse en la misma VPC con los subnets y security groups adecuados.
2. S3 Event Notification: Configura el bucket S3 para que active un evento cuando se suba un archivo:
   - **Evento:** `s3:ObjectCreated: *`.
   - **Destino:** `Lambda Function`.

### Configuraci贸n de Amazon Redshift
Cargar directamente desde S3 a Redshift usando el comando `COPY`.
```sql
COPY transcription_results
FROM 's3://<S3_BUCKET_NAME>/<processed_file>'
CREDENTIALS 'aws_access_key_id=<ACCESS_KEY>;aws_secret_access_key=<SECRET_KEY>'
FORMAT AS JSON 'auto';
```
### Variables de Entorno
- `S3_BUCKET`
- `REDSHIFT_HOST`
- `REDSHIFT_PORT`
- `REDSHIFT_DB`
- `REDSHIFT_USER`
- `REDSHIFT_PASSWORD`
- `REDSHIFT_TABLE`



## 4. Monitoreo y Observabilidad 
El sistema de monitoreo utiliza **CloudWatch** y **Grafana** para visualizar m茅tricas, rastrear el rendimiento y configurar alertas para detectar fallos cr铆ticos.

### Configuraci贸n del monitoreo en Amazon EKS
AWS proporciona un addon llamado **Container Insights** que integra m茅tricas del cl煤ster EKS en CloudWatch, siguiendo los siguientes pasos,
1. Instalar el agente de CloudWatch en EKS:
   ```bash
   kubectl apply -f https://raw.githubusercontent.com/aws/amazon-cloudwatch-agent/main/kubernetes/cloudwatch-agent.yaml
   ```
2. Crea un rol IAM para el agente de CloudWatch que permita enviar m茅tricas y logs a CloudWatch (`polities/cloudwatch.json`).
3. Verifica logs y m茅tricas que env铆en al namespace en CloudWatch.

### Monioreo del cl煤ster EKS y Lambda Functions
- Duraci贸n de la ejecuci贸n: Tiempo que toma la funci贸n en completarse.
- Tasa de invocaci贸n: N煤mero de ejecuciones por minuto.
- Errores: N煤mero de errores durante la ejecuci贸n.
- Utilizaci贸n de CPU y memoria por nodo.
- Estado de los pods (running, pending, failed).
- Tasa de errores en servicios.

Ejemplo de consulta de logs para mostrar errores en aplicaciones:
```bash
fields @timestamp, @message
| filter @message like /ERROR/
| sort @timestamp desc
```

### **Integraci贸n con Grafana**
1. **Conectar Grafana a CloudWatch**:
   - Instala el plugin de CloudWatch en Grafana.
   - Configura una nueva fuente de datos con las credenciales de AWS.
   - Configura un intervalo de actualizaci贸n (por ejemplo, cada 1 minuto).
2. **Crear dashboards personalizados en Grafana**:
   - **Panel EKS**:
     - CPU/Memory por nodo.
     - Estado de los pods por namespace.
     - Tr谩fico entrante/saliente de servicios (HTTP, gRPC).
   - **Panel Lambda**:
     - Duraci贸n, errores y tasa de invocaci贸n.
3. **Configuraci贸n del archivo `grafana-dashboard.json`**: Exporta el dashboard para compartirlo o reutilizarlo.

### CloudWatch Alarms
- **Condici贸n**: `Errors > 0` en un per铆odo de 5 minutos.
- **Acci贸n**: Env铆a notificaci贸n a un SNS topic.
- **Configuraci贸n**:
  ```bash
  aws cloudwatch put-metric-alarm \
    --alarm-name "LambdaErrorAlarm" \
    --metric-name Errors \
    --namespace AWS/Lambda \
    --statistic Sum \
    --period 300 \
    --threshold 0 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 1 \
    --alarm-actions arn:aws:sns:<region>:<account-id>:<sns-topic-name>
  ```
### Configurar alertas en Grafana
- Define alertas en las m茅tricas clave (CPU, errores Lambda, tr谩fico de red).
- Configura canales de notificaci贸n (Slack, email, PagerDuty).



## 5. Preguntas Te贸ricas 
### **1. 驴C贸mo garantizar铆as la seguridad de las credenciales almacenadas en los pipelines?**
1. **Almacenamiento en gestores de secretos:**
   - Utilizar servicios como **AWS Secrets Manager** para almacenar credenciales sensibles (tokens, claves API, contrase帽as).
   - Acceder a las credenciales directamente desde el pipeline mediante integraciones con estos gestores.
2. **Variables de entorno cifradas:**
   - Configurar las credenciales como variables de entorno en los sistemas CI/CD (GitHub Actions, Jenkins, GitLab).
   - Asegurarse de que estas variables est茅n cifradas y solo accesibles durante la ejecuci贸n del pipeline.
3. **Principio de menor privilegio:**
   - Asignar solo los permisos estrictamente necesarios para cada credencial.
   - Usar roles IAM temporales en lugar de credenciales est谩ticas para interactuar con servicios como AWS.
4. **Rotaci贸n autom谩tica de credenciales:**
   - Implementar mecanismos de rotaci贸n peri贸dica para las credenciales.
   - Automatizar la actualizaci贸n de los secretos almacenados.

#### 2. Explica una estrategia para escalar din谩micamente los microservicios seg煤n la carga de trabajo.
1. **Configurar un controlador de escalado autom谩tico (Horizontal Pod Autoscaler - HPA):** En un cl煤ster Kubernetes, usar el **HPA** para ajustar el n煤mero de pods seg煤n las m茅tricas observadas.
2. **Uso de escalado vertical autom谩tico (Vertical Pod Autoscaler - VPA):** Ajusta los recursos asignados (CPU/memoria) a los pods individuales en funci贸n de la carga.
3. **Escalado basado en eventos:**
   - Utilizar soluciones como **KEDA** (Kubernetes Event-Driven Autoscaler) para escalar microservicios seg煤n eventos, como mensajes en una cola (Amazon SQS, Kafka) o solicitudes HTTP.
4. **Pruebas de estr茅s y ajuste de l铆mites:**
   - Realizar pruebas de carga para determinar los l铆mites de cada servicio.
   - Configurar pol铆ticas de calidad de servicio (QoS) en Kubernetes para priorizar recursos.

Con esta estrategia, los microservicios pueden responder din谩micamente a la carga de trabajo, manteniendo la disponibilidad y optimizando el uso de recursos. 



# More Resources
-  [`GitHub Actions`](https://docs.github.com/es/actions/)
-  [`Grafana Documentation`](https://grafana.com/docs/)
-  [`Cloudwatch Documentation`](https://docs.aws.amazon.com/cloudwatch/)
-  [`AWS Documentation`](https://docs.aws.amazon.com/)
-  [`AWS CLI Documentation`](https://docs.aws.amazon.com/cli/index.html/)
-  [`AWS Support`](https://console.aws.amazon.com/support/home#/)