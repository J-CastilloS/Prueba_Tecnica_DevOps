# Prueba T칠cnica para DevOps Senior - Sistemas de IA en AWS
--------------
Configurar una arquitectura en AWS para soportar un modelo de transcripci칩n basado en IA, requiere configurar credenciales AWS con `aws-cli` para gestionar recursos.

#### Requirements
- `Python`: 3.8.x and greater
- `Terraform`: 1.10.4 latest
- `Docker`: 

#### Getting Started
A continuaci칩n, presento los pasos principales con scripts `Terraform <https://www.terraform.io/>` (`/tf/main.tf`) que puedes replicar para implementar la misma arquitectura planteada.
```bash
    terraform init
    terraform validate
    terraform apply
```


## 1. Infraestructura en la Nube
--------------
Terraform mostrar치 los valores como el ID del bucket S3, el nombre del cl칰ster EKS y el ID de la instancia EC2 creada. (`outputs.tf`)
```hcl
    output "s3_bucket_name" {
    value = aws_s3_bucket.data_bucket.id
    }
    output "eks_cluster_name" {
    value = module.eks.cluster_name
    }
    output "ec2_instance_id" {
    value = aws_instance.ml_ec2.id
    }
```
En general, la arquitectura planteada es la siguiente, `Diagrama Excalidraw <https://excalidraw.com/>`,
![cloud_infrastructure](assets\terraform.png)



## 2. Pipeline de CI/CD
--------------
Una soluci칩n basada en **GitHub Actions** que implementa un pipeline CI/CD para el despliegue de un modelo de transcripci칩n en un cl칰ster de EKS. Este pipeline incluye pruebas unitarias, construcci칩n de im치genes Docker y despliegue automatizado.

#### Configuration

1. Secretos en GitHub:
   - `AWS_ACCESS_KEY_ID` y `AWS_SECRET_ACCESS_KEY`: Credenciales de AWS.
2. Manifiestos Kubernetes:
   - Actualizar los archivos `deployment.yaml` y `service.yaml` con las configuraciones necesarias.
3. Imagenes Docker:
   - Configurar un repositorio para almacenar las im치genes Docker del modelo.
4. Cl칰ster EKS:
   - Tener configurado un cl칰ster EKS con los permisos necesarios para el despliegue.



# 3. Gesti칩n de Datos y Data Warehouse 
--------------
Dise침ar un flujo para procesar grabaciones y almacenar resultados en un data warehouse. El pipeline propuesto consta de tres componentes principales:
1. Extracci칩n de datos desde S3: Un evento en S3 (subida de un archivo) activa la funci칩n Lambda.
2. Procesamiento de datos mediante `Lambda`:
   - La funci칩n Lambda procesa la grabaci칩n (transcripci칩n, extracci칩n de metadatos, etc.).
   - Los resultados se formatean en `TABLE`, `JSON` o `CSV` para su carga.
3. Carga en Amazon Redshift: La funci칩n Lambda utiliza la funcionalidad de `COPY` de Redshift para cargar los datos procesados al data warehouse.

#### Amazon Redshift
Esquema de la base de datos con los campos `text` de la transcripci칩n y `timestamp` para verificar la hora de subida y procesamiento,
```sql
CREATE TABLE transcription_results (
    id VARCHAR(50) PRIMARY KEY,
    text TEXT,
    timestamp TIMESTAMP
);
```

#### Permisos IAM
Roles y pol칤ticas necesarias para acceder a S3 y Redshift.
![IAM Polities](assets\iam.png)
1. VPC Lambda: Configurar Lambda para ejecutarse en la misma VPC con los subnets y security groups adecuados.
2. S3 Event Notification: Configura el bucket S3 para que active un evento cuando se suba un archivo:
    - **Evento:** `s3:ObjectCreated: *`.
    - **Destino:** `Lambda Function`.

#### Configuraci칩n de Amazon Redshift
Cargar directamente desde S3 a Redshift usando el comando `COPY`,
```sql
COPY transcription_results
FROM 's3://<S3_BUCKET_NAME>/<processed_file>'
CREDENTIALS 'aws_access_key_id=<ACCESS_KEY>;aws_secret_access_key=<SECRET_KEY>'
FORMAT AS JSON 'auto';
```
#### Variables de Entorno
- `S3_BUCKET`
- `REDSHIFT_HOST`
- `REDSHIFT_PORT`
- `REDSHIFT_DB`
- `REDSHIFT_USER`
- `REDSHIFT_PASSWORD`
- `REDSHIFT_TABLE`



# 4. Monitoreo y Observabilidad 
--------------
El sistema de monitoreo utiliza **CloudWatch** y **Grafana** para visualizar m칠tricas, rastrear el rendimiento y configurar alertas para detectar fallos cr칤ticos.

#### Configuraci칩n del monitoreo en Amazon EKS
AWS proporciona un addon llamado **Container Insights** que integra m칠tricas del cl칰ster EKS en CloudWatch, siguiendo los siguientes pasos,
1. Instalar el agente de CloudWatch en EKS:
   ```bash
   kubectl apply -f https://raw.githubusercontent.com/aws/amazon-cloudwatch-agent/main/kubernetes/cloudwatch-agent.yaml
   ```
2. Crea un rol IAM para el agente de CloudWatch que permita enviar m칠tricas y logs a CloudWatch (`polities/cloudwatch.json`).
3. Verifica logs y m칠tricas que env칤en al namespace en CloudWatch.

#### Monioreo del cl칰ster EKS y Lambda Functions
- Duraci칩n de la ejecuci칩n: Tiempo que toma la funci칩n en completarse.
- Tasa de invocaci칩n: N칰mero de ejecuciones por minuto.
- Errores: N칰mero de errores durante la ejecuci칩n.
- Utilizaci칩n de CPU y memoria por nodo.
- Estado de los pods (running, pending, failed).
- Tasa de errores en servicios.

Ejemplo de consulta de logs para mostrar errores en aplicaciones:
```bash
fields @timestamp, @message
| filter @message like /ERROR/
| sort @timestamp desc
```

#### **Integraci칩n con Grafana**
1. **Conectar Grafana a CloudWatch**:
   - Instala el plugin de CloudWatch en Grafana.
   - Configura una nueva fuente de datos con las credenciales de AWS.
   - Configura un intervalo de actualizaci칩n (por ejemplo, cada 1 minuto).
2. **Crear dashboards personalizados en Grafana**:
   - **Panel EKS**:
     - CPU/Memory por nodo.
     - Estado de los pods por namespace.
     - Tr치fico entrante/saliente de servicios (HTTP, gRPC).
   - **Panel Lambda**:
     - Duraci칩n, errores y tasa de invocaci칩n.
3. **Configuraci칩n del archivo `grafana-dashboard.json`**: Exporta el dashboard para compartirlo o reutilizarlo.

#### CloudWatch Alarms
- **Condici칩n**: `Errors > 0` en un per칤odo de 5 minutos.
- **Acci칩n**: Env칤a notificaci칩n a un SNS topic.
- **Configuraci칩n**:
  ```bash
  aws cloudwatch put-metric-alarm \
    --alarm-name "LambdaErrorAlarm" \
    --metric-name Errors \
    --namespace AWS/Lambda \
    --statistic Sum \
    --period 300 \
    --threshold 0 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 1 \
    --alarm-actions arn:aws:sns:<region>:<account-id>:<sns-topic-name>
  ```
#### Configurar alertas en Grafana
- Define alertas en las m칠tricas clave (CPU, errores Lambda, tr치fico de red).
- Configura canales de notificaci칩n (Slack, email, PagerDuty).



# 5. Preguntas Te칩ricas 
--------------
#### **1. 쮺칩mo garantizar칤as la seguridad de las credenciales almacenadas en los pipelines?**
Se pueden seguir las siguientes estrategias,
1. **Almacenamiento en gestores de secretos:**
   - Utilizar servicios como **AWS Secrets Manager** para almacenar credenciales sensibles (tokens, claves API, contrase침as).
   - Acceder a las credenciales directamente desde el pipeline mediante integraciones con estos gestores.
2. **Variables de entorno cifradas:**
   - Configurar las credenciales como variables de entorno en los sistemas CI/CD (GitHub Actions, Jenkins, GitLab).
   - Asegurarse de que estas variables est칠n cifradas y solo accesibles durante la ejecuci칩n del pipeline.
3. **Principio de menor privilegio:**
   - Asignar solo los permisos estrictamente necesarios para cada credencial.
   - Usar roles IAM temporales en lugar de credenciales est치ticas para interactuar con servicios como AWS.
4. **Rotaci칩n autom치tica de credenciales:**
   - Implementar mecanismos de rotaci칩n peri칩dica para las credenciales.
   - Automatizar la actualizaci칩n de los secretos almacenados.

#### 2. Explica una estrategia para escalar din치micamente los microservicios seg칰n la carga de trabajo.
La escalabilidad din치mica permite ajustar los recursos asignados a los microservicios en funci칩n de la carga de trabajo, mejorando la eficiencia y reduciendo costos. Una estrategia t칤pica incluye,
1. **Configurar un controlador de escalado autom치tico (Horizontal Pod Autoscaler - HPA):** En un cl칰ster Kubernetes, usar el **HPA** para ajustar el n칰mero de pods seg칰n las m칠tricas observadas.
2. **Uso de escalado vertical autom치tico (Vertical Pod Autoscaler - VPA):** Ajusta los recursos asignados (CPU/memoria) a los pods individuales en funci칩n de la carga.
3. **Escalado basado en eventos:**
   - Utilizar soluciones como **KEDA** (Kubernetes Event-Driven Autoscaler) para escalar microservicios seg칰n eventos, como mensajes en una cola (Amazon SQS, Kafka) o solicitudes HTTP.
4. **Pruebas de estr칠s y ajuste de l칤mites:**
   - Realizar pruebas de carga para determinar los l칤mites de cada servicio.
   - Configurar pol칤ticas de calidad de servicio (QoS) en Kubernetes para priorizar recursos.

Con esta estrategia, los microservicios pueden responder din치micamente a la carga de trabajo, manteniendo la disponibilidad y optimizando el uso de recursos. 游땕



# More Resources
--------------
-  `GitHub Actions <https://docs.github.com/es/actions/>`
-  `Grafana Documentation <https://grafana.com/docs/>`
-  `Cloudwatch Documentation <https://docs.aws.amazon.com/cloudwatch/>`
-  `AWS Documentation <https://docs.aws.amazon.com/>`
-  `AWS CLI Documentation <https://docs.aws.amazon.com/cli/index.html/>`
-  `AWS Support <https://console.aws.amazon.com/support/home#/>`